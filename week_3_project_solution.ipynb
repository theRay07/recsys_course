{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a424b415-b8ef-47b3-84ee-7c40332e01ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a424b415-b8ef-47b3-84ee-7c40332e01ef",
        "outputId": "6e075d43-d67c-4ee3-fcf2-0852c1a7d821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.7/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu --no-cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837dcaa9-cc0b-4345-bbee-3a09683decf9",
      "metadata": {
        "id": "837dcaa9-cc0b-4345-bbee-3a09683decf9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import faiss\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f1f7cb-9441-4fe1-962e-9e4cb3e3c192",
      "metadata": {
        "id": "41f1f7cb-9441-4fe1-962e-9e4cb3e3c192"
      },
      "source": [
        "# **Welcome to week 3 project!**\n",
        "\n",
        "Congratulations on making it to week 3! üëè In the first week of this course, we covered the basics of how to design personalized recommendation systems. We then provided some system design examples for large scale recommenders from corporations like Spotify and YouTube, as well as techniques for candidate generation, specifically the two-tower model being used at Twitter and Pinterest.\n",
        "\n",
        "Last week, we covered details of ML approaches for recommendations: including multi-task recommenders and contextual bandits.\n",
        "\n",
        "In week 3, we covered various techniques for learning user representations.\n",
        "\n",
        "In this week's project, we will touch upon two key aspects related to representations:\n",
        "1. How do we query large amount of vectors in efficient time.\n",
        "2. How can we infer various user representations and see what their impact is on downstream task.\n",
        "\n",
        "Lets begin with Part A, which tells us how we could handle a large number of candidate items or user representations in an efficient manner. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e01328-6834-4b11-85c1-03867e1d4860",
      "metadata": {
        "id": "d0e01328-6834-4b11-85c1-03867e1d4860"
      },
      "source": [
        "# Part A: Approximate nearest neighbor search\n",
        "\n",
        "Often we are interested in finding nearest neighbors in a large space of vectors. To store embeddings for 400 million users and over 100 million items and querying them in real time is a challenging task. This is where approximate nearest neighbor approaches step in to help. Annoy, Faiss, ScaNN are typical libraries that are used for efficient vector similarity search at scale. They implement algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM.\n",
        "\n",
        "In the first part of this week's project, we will simulate embeddings of 1 million items and try to find k-nearest neighbours for an item of interest. We will implement a vanilla search function to fetch the top-k nearest neighbors and estimate the time it takes for us to do so. We will then compare this with FAISS -- Facebook's nearest neighbour search library, and compare the time it takes for us to get nearest neighbours from FAISS versus our own implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fa2b438-be53-4f39-b990-859046a4a560",
      "metadata": {
        "id": "3fa2b438-be53-4f39-b990-859046a4a560"
      },
      "source": [
        "Lets first generate a simulated dataset of embeddings of 1 million items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c36fc8b-a032-4b48-bbeb-3bff46624615",
      "metadata": {
        "id": "8c36fc8b-a032-4b48-bbeb-3bff46624615"
      },
      "outputs": [],
      "source": [
        "d = 64                           # dimension\n",
        "nb = 1000000                     # database size\n",
        "nq = 10000                       # nb of queries\n",
        "np.random.seed(1234)             # make reproducible\n",
        "xb = np.random.random((nb, d)).astype('float32')\n",
        "xq = np.random.random((nq, d)).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142c00a5-f36b-4a5f-9e27-4a3e38b467d7",
      "metadata": {
        "id": "142c00a5-f36b-4a5f-9e27-4a3e38b467d7"
      },
      "source": [
        "Now that we have these items, lets take up the goal of finding the top-5 items closest to this specific item. Your goal is to implement your function to estimate the top-5 items and print the average distance of these top 5 items to the query item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2dd70b9-8d2c-4134-b866-ab09af43a47d",
      "metadata": {
        "id": "b2dd70b9-8d2c-4134-b866-ab09af43a47d"
      },
      "outputs": [],
      "source": [
        "k=5\n",
        "query_vector = xq[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TLecYVveiOBs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLecYVveiOBs",
        "outputId": "eb5302be-5187-4b2f-d33b-7f7ba6aeb4b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 64)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m-L0BQ2EiN0y",
      "metadata": {
        "id": "m-L0BQ2EiN0y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a94ee2-3131-44c5-ba95-ec67aa675048",
      "metadata": {
        "id": "84a94ee2-3131-44c5-ba95-ec67aa675048"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def find_top_k_nn(query_vector,k):\n",
        "    \"\"\"\n",
        "    in this function, implement your definition of top-k nearest neighbours, and return the distances\n",
        "    and indices of the these top-k items.\n",
        "    \"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(xb)\n",
        "    distances, indices = nbrs.kneighbors(query_vector)\n",
        "    return [distances, indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a895ce-4f0b-41a5-8243-90f18bff8d7b",
      "metadata": {
        "id": "b8a895ce-4f0b-41a5-8243-90f18bff8d7b"
      },
      "source": [
        "With your top-k NN function implemented, call this function to get the top-k nearest neighbor items for the query_vector and print the average distance. Also, print the time it takes to run this function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df9e9f8-a854-4896-9ebd-fd74bad21690",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df9e9f8-a854-4896-9ebd-fd74bad21690",
        "outputId": "745fc848-1cba-4240-cf70-e5b3cfc0a27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distances from the k nearest neighbor fetched: [[2.07322039 2.15825516 2.18514396 2.19588514 2.20543758]\n",
            " [2.07733144 2.10835827 2.12688584 2.15298    2.15415274]\n",
            " [2.17769585 2.24855261 2.24976079 2.25900216 2.26254754]\n",
            " [2.18702319 2.20928457 2.21616265 2.23459638 2.24518106]\n",
            " [2.14518785 2.16852588 2.22615702 2.22826085 2.26510717]\n",
            " [2.2149673  2.22456618 2.22705486 2.2944823  2.29916712]\n",
            " [2.34783916 2.38612009 2.39604006 2.41502008 2.44981534]\n",
            " [2.11695607 2.1274201  2.13203016 2.19697398 2.20086319]\n",
            " [2.07445545 2.08845956 2.1768757  2.18839431 2.20085277]\n",
            " [2.14081069 2.17164337 2.18274729 2.18579233 2.19879951]]\n",
            "indices from the k nearest neighbor fetched: [[569287  66887 250759 993911 524294]\n",
            " [283299  60712 919090  12255 569275]\n",
            " [934893 201968 529281 836119 808216]\n",
            " [312072 237245 658564 715952 435551]\n",
            " [ 38625 685376 950449 162479 335711]\n",
            " [297024 544719 230987 262829 649140]\n",
            " [708960 250395 687708  88700 872965]\n",
            " [970917 932769 979449 833489 969787]\n",
            " [480686 641040  83274 827866 149021]\n",
            " [273655 581676 815362 163220  39267]]\n",
            "average distance of the k- nearest neighbors fetched:  2.2079768610300095\n",
            "CPU times: user 24.6 s, sys: 269 ms, total: 24.9 s\n",
            "Wall time: 33.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "D, I = find_top_k_nn(query_vector, k)\n",
        "print(\"distances from the k nearest neighbor fetched:\",D)\n",
        "print(\"indices from the k nearest neighbor fetched:\",I)\n",
        "print(\"average distance of the k- nearest neighbors fetched: \",D.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd4452f5-ce17-43df-95f2-e9b58e8cad5e",
      "metadata": {
        "id": "bd4452f5-ce17-43df-95f2-e9b58e8cad5e"
      },
      "source": [
        "Now lets switch to using Faiss https://github.com/facebookresearch/faiss\n",
        "\n",
        "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6427be9-53b2-446c-851b-b2f6b7db9fa6",
      "metadata": {
        "id": "b6427be9-53b2-446c-851b-b2f6b7db9fa6"
      },
      "source": [
        "### Similarity search in Faiss\n",
        "\n",
        "Given a set of vectors x_i in dimension d, Faiss builds a data structure in RAM. After the structure is constructed, when given a new vector x in dimension d it performs efficiently the operation:\n",
        "\n",
        "$i = argmin_i ||x - x_i||$\n",
        "\n",
        "where ||.|| is the Euclidean distance (L2).\n",
        "\n",
        "In Faiss terms, the data structure is an index, an object that has an add method to add x_i vectors. Note that the x_i's are assumed to be fixed. Computing the argmin is the search operation on the index.\n",
        "\n",
        "### Indexes used by Faiss\n",
        "\n",
        "1. The inverted file from ‚ÄúVideo google: A text retrieval approach to object matching in videos.‚Äù, Sivic & Zisserman, ICCV 2003. This is the key to non-exhaustive search in large datasets. Otherwise all searches would need to scan all elements in the index, which is prohibitive even if the operation to apply for each element is fast\n",
        "\n",
        "\n",
        "2. The product quantization (PQ) method from ‚ÄúProduct quantization for nearest neighbor search‚Äù, J√©gou & al., PAMI 2011. This can be seen as a lossy compression technique for high-dimensional vectors, that allows relatively accurate reconstructions and distance computations in the compressed domain.\n",
        "\n",
        "\n",
        "3. The three-level quantization (IVFADC-R aka IndexIVFPQR) method from \"Searching in one billion vectors: re-rank with source coding\", Tavenard & al., ICASSP'11."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e63810d-fd22-49ca-b4bd-423ebf348c5f",
      "metadata": {
        "id": "3e63810d-fd22-49ca-b4bd-423ebf348c5f"
      },
      "source": [
        "We will implement these three indexes from faiss and use each of these three to search the index, and get the top-k nearest neighbour vectors, and estimate the average distance.\n",
        "\n",
        "Lets first construct the three indexes: index1, index2, index3 based on Flat index, Inverted index and product quantization techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76487ec4-a020-4ccd-aa33-f6ef25869048",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76487ec4-a020-4ccd-aa33-f6ef25869048",
        "outputId": "29903a27-b1cd-44d2-80aa-a69bd4d48488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total number of vectors indexed =  1000000\n",
            "CPU times: user 99.1 ms, sys: 999 ¬µs, total: 100 ms\n",
            "Wall time: 139 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "index1 = faiss.IndexFlatL2(d)   # build the index\n",
        "index1.add(xb)                  # add vectors to the index\n",
        "print(\"total number of vectors indexed = \",index1.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55447035-57e2-4938-837b-9bf20bf66ff6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55447035-57e2-4938-837b-9bf20bf66ff6",
        "outputId": "46901220-8d4e-4f0f-85c8-5a1d811e4989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total number of vectors indexed =  1000000\n",
            "CPU times: user 3.14 s, sys: 43.5 ms, total: 3.18 s\n",
            "Wall time: 3.11 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "nlist = 100\n",
        "quantizer = faiss.IndexFlatL2(d)  # the other index\n",
        "index2 = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
        "index2.train(xb)\n",
        "index2.add(xb)\n",
        "print(\"total number of vectors indexed = \",index2.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f04ebe3c-705d-49b2-aa7b-3602c111c754",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04ebe3c-705d-49b2-aa7b-3602c111c754",
        "outputId": "ab15b345-6dc8-45fc-83fe-69e18d8a4f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total number of vectors indexed =  1000000\n",
            "CPU times: user 47.6 s, sys: 153 ms, total: 47.7 s\n",
            "Wall time: 32.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "nlist = 100\n",
        "m = 8\n",
        "quantizer = faiss.IndexFlatL2(d)  # this remains the same\n",
        "index3 = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8)\n",
        "                                  # 8 specifies that each sub-vector is encoded as 8 bits\n",
        "index3.train(xb)\n",
        "index3.add(xb)\n",
        "print(\"total number of vectors indexed = \",index3.ntotal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047a6682-f771-4672-8998-307f4cfad5f5",
      "metadata": {
        "id": "047a6682-f771-4672-8998-307f4cfad5f5"
      },
      "source": [
        "Now that we have these three indexes, let us query these to fetch the top-k nearest neghbour for our query_vector and compute the average distance we obtain for each.\n",
        "\n",
        "We will also time these commands, to find out the trade-off between accuracy and latency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e54dc7d-5d15-47b2-85e4-c583f92d52a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e54dc7d-5d15-47b2-85e4-c583f92d52a8",
        "outputId": "73cd4dcc-a910-4335-a1c0-c7ccedd32447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distances from the k nearest neighbor fetched: [[4.298243  4.658066  4.774853  4.821912  4.863956 ]\n",
            " [4.3153067 4.445174  4.523643  4.6353226 4.640375 ]\n",
            " [4.742359  5.055989  5.0614223 5.1030912 5.1191216]\n",
            " [4.78307   4.880938  4.911376  4.9934206 5.0408382]\n",
            " [4.601831  4.702504  4.9557753 4.965146  5.1307116]\n",
            " [4.906081  4.9486947 4.959773  5.2646484 5.2861695]\n",
            " [5.5123487 5.6935697 5.7410083 5.8323216 6.0015945]\n",
            " [4.481503  4.525917  4.5455523 4.8266945 4.843798 ]\n",
            " [4.303365  4.361663  4.738787  4.7890697 4.843754 ]\n",
            " [4.5830703 4.716036  4.7643847 4.777689  4.834718 ]]\n",
            "indices from the k nearest neighbor fetched: [[569287  66887 250759 993911 524294]\n",
            " [283299  60712 919090  12255 569275]\n",
            " [934893 201968 529281 836119 808216]\n",
            " [312072 237245 658564 715952 435551]\n",
            " [ 38625 685376 950449 162479 335711]\n",
            " [297024 544719 230987 262829 649140]\n",
            " [708960 250395 687708  88700 872965]\n",
            " [970917 932769 979449 833489 969787]\n",
            " [480686 641040  83274 827866 149021]\n",
            " [273655 581676 815362 163220  39267]]\n",
            "average distance of the k- nearest neighbors fetched:  4.8821335\n",
            "CPU times: user 777 ms, sys: 6.97 ms, total: 784 ms\n",
            "Wall time: 413 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "D, I = index1.search(query_vector, k)\n",
        "print(\"distances from the k nearest neighbor fetched:\", D)\n",
        "print(\"indices from the k nearest neighbor fetched:\", I)\n",
        "print(\"average distance of the k- nearest neighbors fetched: \", D.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be8f1b17-6108-41fd-814c-caa996fb731d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be8f1b17-6108-41fd-814c-caa996fb731d",
        "outputId": "73831243-efd2-4fce-b52d-c1b2b5205cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distances from the k nearest neighbor fetched: [[4.975559  5.435684  5.488215  5.5291057 5.6262336]\n",
            " [4.6353226 5.27126   5.439318  5.4742155 5.4852448]\n",
            " [5.1839685 5.4732704 5.579998  5.5801306 5.5917964]\n",
            " [5.1358366 5.186938  5.2274795 5.5377507 5.6002126]\n",
            " [5.3008466 5.6537685 5.6843395 5.7451887 5.7546577]\n",
            " [4.906081  4.9486947 5.4694433 5.6031375 5.924646 ]\n",
            " [5.8323216 6.402934  6.6648207 6.7098503 6.756767 ]\n",
            " [5.400519  5.7103963 5.724591  5.8267198 5.8431997]\n",
            " [4.738787  4.889336  5.2342777 5.3129263 5.327965 ]\n",
            " [5.041148  5.083842  5.148944  5.2724133 5.406432 ]]\n",
            "indices from the k nearest neighbor fetched: [[121366 479596 389435 971983 247236]\n",
            " [ 12255 782326 214405 244615 234623]\n",
            " [ 95006 255141 567851 445550 170825]\n",
            " [130029 623417 736000 286931  27894]\n",
            " [190635 600529 967693 948683 332062]\n",
            " [297024 544719  53726 485242 570300]\n",
            " [ 88700 487048 824129 521457 199274]\n",
            " [ 23801 452759 334706 824243  82794]\n",
            " [ 83274 689668 999841 646263 244018]\n",
            " [230573 345705 640082 483264 113207]]\n",
            "average distance of the k- nearest neighbors fetched:  5.4955306\n",
            "CPU times: user 17.7 ms, sys: 0 ns, total: 17.7 ms\n",
            "Wall time: 12.4 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "D, I = index2.search(query_vector, k)\n",
        "print(\"distances from the k nearest neighbor fetched:\", D)\n",
        "print(\"indices from the k nearest neighbor fetched:\", I)\n",
        "print(\"average distance of the k- nearest neighbors fetched: \", D.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b230291-517c-49c5-a634-f9d4d331e241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b230291-517c-49c5-a634-f9d4d331e241",
        "outputId": "9be0995a-b5c1-4a1f-ae8e-98661b2dd786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distances from the k nearest neighbor fetched: [[4.683815  4.7687855 4.798374  4.922883  5.0278025]\n",
            " [4.4225907 4.772164  4.8459597 4.8811245 4.963088 ]\n",
            " [4.8449755 4.938947  4.9456244 5.156204  5.361733 ]\n",
            " [4.7844825 4.8936176 4.973062  5.0239005 5.0711923]\n",
            " [4.7346063 5.030787  5.053102  5.085321  5.189575 ]\n",
            " [4.637653  4.941787  4.956658  5.2324824 5.259699 ]\n",
            " [5.8392434 5.8662605 5.9031625 5.907941  5.9541783]\n",
            " [4.282753  4.9999533 5.0521717 5.1036    5.128742 ]\n",
            " [4.1714187 4.2498884 4.333894  4.3577514 4.364253 ]\n",
            " [3.8721733 4.30189   4.5027285 4.680484  4.7891617]]\n",
            "indices from the k nearest neighbor fetched: [[747510 295760  37358  87025 173853]\n",
            " [ 12255 244615 300287 454110   3396]\n",
            " [498344 751562 118396  95006 560682]\n",
            " [ 60082 678212 553596 855705  69252]\n",
            " [190635 668846 620307 903755   8315]\n",
            " [544719 881379 120010 776807 436424]\n",
            " [521457 323255 615136 275231 487048]\n",
            " [274882 418923  65885 242036 242282]\n",
            " [133067 644153 807618  83274 592408]\n",
            " [944192 854982 947945 376438  82821]]\n",
            "average distance of the k- nearest neighbors fetched:  4.917273\n",
            "CPU times: user 9.75 ms, sys: 956 ¬µs, total: 10.7 ms\n",
            "Wall time: 9.65 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "D, I = index3.search(query_vector, k)\n",
        "print(\"distances from the k nearest neighbor fetched:\", D)\n",
        "print(\"indices from the k nearest neighbor fetched:\", I)\n",
        "print(\"average distance of the k- nearest neighbors fetched: \", D.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c902e3-c9bf-408e-9052-11af5a3b069f",
      "metadata": {
        "id": "c2c902e3-c9bf-408e-9052-11af5a3b069f"
      },
      "source": [
        "Running all these, we observe that the product quantization based index is an order of magnitude faster than the inverted index. In terms of accuracy, if we assume that the lower the distance the more accurate the result, FlatIndex gives us the least distance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044a818f-19ab-4c26-8532-922c9aa1d673",
      "metadata": {
        "id": "044a818f-19ab-4c26-8532-922c9aa1d673"
      },
      "source": [
        "### Goal 1 for this week: Implement your k-NN function and time it\n",
        "\n",
        "The main goal for this part of the project is to implement your vanilla nearest neighbor function and fetch the closest k nearest neighbours to the query vector. Important to note that your implementation will give an exact result, i.e., your implementation will find the exact closest k vectors that will give the minimum distance to the query_vector.\n",
        "\n",
        "Please compile the results in a table, and compare the average distance obtained and the time it took to query the 1 million vectors. A nice 2D plot would also give you a good idea of the speed-accuracy trade-off involved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e69dd09-6a21-49a8-8ca8-4d5164a7e674",
      "metadata": {
        "id": "2e69dd09-6a21-49a8-8ca8-4d5164a7e674"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def experiment(query_vector, k, func_dict):\n",
        "  results = {}\n",
        "  for name, func in func_dict.items():\n",
        "    faiss = False\n",
        "    if 'faiss' in name:\n",
        "        faiss=True\n",
        "    t, mu = time_trial(func, query_vector, k, faiss=faiss)\n",
        "    results[name] = {\n",
        "        'time': t,\n",
        "        'avg_distance': mu\n",
        "    }\n",
        "\n",
        "  return results\n",
        "\n",
        "def time_trial(func, query_vector, k, faiss):\n",
        "    start_time = time.time()\n",
        "    if faiss:\n",
        "        D, _ = func.search(query_vector, k)\n",
        "    else:\n",
        "        D, _ = func(query_vector, k)\n",
        "    t = time.time() - start_time\n",
        "    return t, D.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZVmn36ituZHQ",
      "metadata": {
        "id": "ZVmn36ituZHQ"
      },
      "outputs": [],
      "source": [
        "k=5\n",
        "query_vector = xq[0:10]\n",
        "func_dict = {\n",
        "    'knn': find_top_k_nn,\n",
        "    'faiss_inverted_file': index1,\n",
        "    'faiss_product_quantization': index2,\n",
        "    'faiss_three_level_quantization': index3\n",
        "}\n",
        "\n",
        "exp_results = experiment(query_vector, k, func_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Zs-sc5vvidv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "9Zs-sc5vvidv",
        "outputId": "2e1b1c65-c8ee-495d-dc8a-26a9e43bce2b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "results_df = (\n",
        "    pd.DataFrame.from_dict(exp_results, orient='index')\n",
        "    .reset_index()\n",
        "    .rename(columns={'index': 'method'})\n",
        ")\n",
        "\n",
        "sns.scatterplot(data=results_df, x=\"time\", y=\"avg_distance\", hue='method');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FBLNqVjROHEU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "FBLNqVjROHEU",
        "outputId": "a5cc78dc-2838-476e-961e-28e1f617df9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57386484-2c8e-4090-b96c-597c6cdc188e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>time</th>\n",
              "      <th>avg_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>knn</td>\n",
              "      <td>17.114147</td>\n",
              "      <td>2.207977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>faiss_inverted_file</td>\n",
              "      <td>0.384089</td>\n",
              "      <td>4.882133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>faiss_product_quantization</td>\n",
              "      <td>0.003819</td>\n",
              "      <td>5.495531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>faiss_three_level_quantization</td>\n",
              "      <td>0.000774</td>\n",
              "      <td>4.917273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57386484-2c8e-4090-b96c-597c6cdc188e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57386484-2c8e-4090-b96c-597c6cdc188e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57386484-2c8e-4090-b96c-597c6cdc188e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           method       time  avg_distance\n",
              "0                             knn  17.114147      2.207977\n",
              "1             faiss_inverted_file   0.384089      4.882133\n",
              "2      faiss_product_quantization   0.003819      5.495531\n",
              "3  faiss_three_level_quantization   0.000774      4.917273"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e127987e-44f9-43b3-9219-1036edd0d14c",
      "metadata": {
        "id": "e127987e-44f9-43b3-9219-1036edd0d14c"
      },
      "source": [
        "# Part B: User representations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13c18e33-3a62-4afe-95af-9d33ef87917c",
      "metadata": {
        "id": "13c18e33-3a62-4afe-95af-9d33ef87917c"
      },
      "source": [
        "In the second part of this week's project, we wish to understand few ways of estimating user representations, and how it impacts the performance of downstream tasks.\n",
        "\n",
        "To this end, we will work on top of our H&M dataset, and develop a few different ways of representing users.\n",
        "\n",
        "The broader framework here will be -- we fix the article representations, and fix the downstream task, and then vary the user representations and see how the performance of the downstream task changes based on different user representation techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd824205-1569-4b54-8c48-fda93a59053d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd824205-1569-4b54-8c48-fda93a59053d",
        "outputId": "5a2350a2-2985-4317-c0cf-5807aed63144",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "251abdd1-1cd4-41f9-af70-23d22a1aa455",
      "metadata": {
        "id": "251abdd1-1cd4-41f9-af70-23d22a1aa455"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import random\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import lightgbm as lgb\n",
        "import datetime\n",
        "import itertools\n",
        "import os\n",
        "from contextlib import redirect_stdout\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "219f3784-220e-4889-ae88-09c80f556479",
      "metadata": {
        "id": "219f3784-220e-4889-ae88-09c80f556479"
      },
      "source": [
        "While we have used neural models so far, lets try a tree based model for this task. We use LightGBM library to train the main model. Lets set up few parameters for the lightgbm model, and specify some additional parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e76b18-8d9e-4a1b-bf84-a929c8f16c6f",
      "metadata": {
        "id": "21e76b18-8d9e-4a1b-bf84-a929c8f16c6f"
      },
      "outputs": [],
      "source": [
        "rand = 64\n",
        "lgb_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"boosting\": \"gbdt\",\n",
        "    \"max_depth\": -1,\n",
        "    \"num_leaves\": 40,\n",
        "    \"subsample\": 0.8,\n",
        "    \"subsample_freq\": 1,\n",
        "    \"bagging_seed\": rand,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"feature_fraction\": 0.6,\n",
        "    \"min_data_in_leaf\": 100,\n",
        "    \"lambda_l1\": 0,\n",
        "    \"lambda_l2\": 0,\n",
        "    \"random_state\": rand,\n",
        "    \"metric\": \"auc\",#\"binary_logloss\",\n",
        "    \"verbose\": -1\n",
        "}\n",
        "\n",
        "tran_dtypes = {\"t_dat\":\"str\",\n",
        "               \"customer_id\":\"str\",\n",
        "               \"article_id\":\"int\",\n",
        "               \"product_code\":\"int\",\n",
        "               \"price\":\"float\",\n",
        "               \"sales_channel_id\":\"int\"}\n",
        "art_dtypes = {\"article_id\":\"int\",\n",
        "              \"product_code\":\"int\",\n",
        "              \"product_type_no\":\"int\",\n",
        "              \"graphical_appearance_no\":\"int\",\n",
        "              \"colour_group_code\":\"int\",\n",
        "              \"department_no\":\"int\",\n",
        "              \"index_code\":\"str\",\n",
        "              \"index_group_no\":\"int\",\n",
        "              \"section_no\":\"int\",\n",
        "              \"garment_group_no\":\"int\"}\n",
        "cust_dtypes = {\"customer_id\":\"str\"}\n",
        "\n",
        "obj = \"class\" # \"class\" or \"rank\"\n",
        "N = 15000\n",
        "n_iter = 2 # num of iteration\n",
        "idx_file = \"exp1\"\n",
        "n_round = 2000\n",
        "n_splits = 1\n",
        "nobuy = 20 # num of negative samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df9c2e0-af9e-406d-a9c6-c38a87347728",
      "metadata": {
        "id": "3df9c2e0-af9e-406d-a9c6-c38a87347728"
      },
      "source": [
        "While we vary the user represnetations, we will keep the article representation fixed. The code below reads the article.csv file and extracts a number of features to represent articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb93a7cd-a637-4960-9577-08449a57b55d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb93a7cd-a637-4960-9577-08449a57b55d",
        "outputId": "f615cb36-75cc-4b51-a8a6-d392c881653e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"hmdata/articles.csv.zip\")\n",
        "\n",
        "## Find categorical columns\n",
        "ohe_columns = []\n",
        "total = 0\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"int64\" and len(df[col].unique()) <= 500:\n",
        "        ohe_columns.append(col)\n",
        "        total += len(df[col].unique())\n",
        "        \n",
        "## Do one hot encoding of the above categorical variables\n",
        "V = pd.get_dummies(df[ohe_columns], columns=ohe_columns).values\n",
        "\n",
        "\n",
        "## Get article features\n",
        "tfidf = TfidfVectorizer(min_df=3)\n",
        "V_desc = tfidf.fit_transform(df[\"detail_desc\"].fillna(\"nodesc\"))\n",
        "\n",
        "## Represent articles as vector of size 512\n",
        "EMB_SIZE = 512\n",
        "V = np.hstack([V.astype(\"float32\"), V_desc.todense()])\n",
        "svd = TruncatedSVD(n_components=EMB_SIZE, random_state=0)\n",
        "svd.fit(V)\n",
        "V = svd.transform(V)\n",
        "\n",
        "np.save(\"articles.npy\", V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a3715e-de70-49d4-b057-e0b674ca65ff",
      "metadata": {
        "id": "64a3715e-de70-49d4-b057-e0b674ca65ff"
      },
      "outputs": [],
      "source": [
        "def item_representation_1():\n",
        "    df_art = pd.read_csv(\"hmdata/articles.csv.zip\",dtype=art_dtypes)\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df_art[\"index_code\"].unique())\n",
        "    df_art[\"index_code\"] = le.transform(df_art[\"index_code\"])\n",
        "    \n",
        "    dict_vec = {}\n",
        "    vec_art = np.load(\"articles.npy\")\n",
        "    df_vec = pd.concat([df_art[\"article_id\"],pd.DataFrame(vec_art)],axis=1)\n",
        "    for i in range(len(vec_art)):\n",
        "        dict_vec[df_art[\"article_id\"][i]] = vec_art[i]\n",
        "    del vec_art,df_vec\n",
        "    \n",
        "    return df_art, dict_vec\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cbe5f64-354c-451e-a9e0-eb114440f8f0",
      "metadata": {
        "id": "7cbe5f64-354c-451e-a9e0-eb114440f8f0"
      },
      "source": [
        "Taken together, the two cells above give us all the features we want to represent articles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c3082e-1da7-466f-8b9f-c777c8ef63cd",
      "metadata": {
        "id": "f0c3082e-1da7-466f-8b9f-c777c8ef63cd"
      },
      "source": [
        "Now lets define some functions to extract user representations. The different functions will contain different ways of representing users.\n",
        "\n",
        "We bootstrap by providing a simple set of features to represent users in user_representation_1(). This function returns the dataframe of user features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de63a95-ef6c-4796-8e59-0cb33b9b948e",
      "metadata": {
        "id": "5de63a95-ef6c-4796-8e59-0cb33b9b948e"
      },
      "outputs": [],
      "source": [
        "def user_representation_1():\n",
        "    df_cust = pd.read_csv(\"hmdata/customers.csv.zip\",dtype=cust_dtypes)\n",
        "    df_cust[\"age\"] = df_cust[\"age\"].fillna(df_cust[\"age\"].mean())\n",
        "    df_cust[[\"FN\",\"Active\"]] = df_cust[[\"FN\",\"Active\"]].fillna(0)\n",
        "    df_cust[\"club_member_status\"] = df_cust[\"club_member_status\"].apply(lambda x:1 if x == \"ACTIVE\" else 0)\n",
        "    df_cust[\"fashion_news_frequency\"] = df_cust[\"fashion_news_frequency\"].apply(lambda x:0 if x == \"NONE\" else 1)\n",
        "    df_cust = df_cust.drop([\"postal_code\"], axis=1)\n",
        "    return df_cust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65dbcef5-701a-4999-b696-3d871ccb485d",
      "metadata": {
        "id": "65dbcef5-701a-4999-b696-3d871ccb485d"
      },
      "outputs": [],
      "source": [
        "def user_representation_2():\n",
        "    \"\"\"\n",
        "    TODO -- compute user representations as the average\n",
        "    of the embeddings of the recently purchased articles\n",
        "    return user representation\n",
        "\n",
        "    Hint: You may find pd.DataFrame(item_representation_1()[1]).transpose() useful\n",
        "    \"\"\"\n",
        "    df_trans = pd.read_csv(\"hmdata/transactions_train.csv.zip\", dtype=tran_dtypes)\n",
        "    df_trans[\"t_dat\"] = pd.to_datetime(df_trans[\"t_dat\"],format=\"%Y-%m-%d\")\n",
        "    day_oldest = datetime.datetime(2018,9,23)\n",
        "    df_trans = df_trans.query(f\"t_dat >= '{day_oldest}'\").copy()\n",
        "    df_trans = df_trans.drop_duplicates([\"customer_id\",\"article_id\"])\n",
        "    df_art_emb = (\n",
        "        pd.DataFrame(item_representation_1()[1]).transpose()\n",
        "        .reset_index()\n",
        "        .rename(columns={'index': 'article_id'})\n",
        "    )\n",
        "    df_cust = (\n",
        "        df_trans.merge(\n",
        "            df_art_emb,\n",
        "            how='left',\n",
        "            on='article_id'\n",
        "        )\n",
        "        .drop('article_id', axis=1)\n",
        "        .groupby('customer_id', as_index=False).mean()\n",
        "    )\n",
        "    return df_cust\n",
        "\n",
        "def user_representation_3():\n",
        "    \"\"\"\n",
        "    OPTIONAL -- compute user representations as the output\n",
        "    of the doc2vec model.\n",
        "    https://cs.stanford.edu/~quocle/paragraph_vector.pdf\n",
        "    Doc2vec model is an embedding learning method\n",
        "    that enables us to learn representations of a document.\n",
        "    We treat each user as a document, and the set of articles\n",
        "    the user has purchased as the set of words in the document.\n",
        "    \"\"\"\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZuHTD5QfRcMo",
      "metadata": {
        "id": "ZuHTD5QfRcMo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d39b7430-bf43-4f16-b7a8-a6edbd078e1d",
      "metadata": {
        "id": "d39b7430-bf43-4f16-b7a8-a6edbd078e1d"
      },
      "source": [
        "As part of the goal for part B of this week's project, please use the above two functions to implement the two user representation techniques mentioned in the project jumpstart.\n",
        "\n",
        "You can run the rest of the notebook for now, and come back to these functions, implement them and re-run some of the code below and use user_representation_2() (and optionally user_representation_3()) to get the appropriate user features to use to train the model for the downstream task.\n",
        "\n",
        "Lets write a function that would read the transactions data and return the dataframes for the transactions within the dates we want to consider, along with the dataframes for articles features: df_art and dict_vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c3e4dd-ce84-4199-9215-06490305db3c",
      "metadata": {
        "id": "55c3e4dd-ce84-4199-9215-06490305db3c"
      },
      "outputs": [],
      "source": [
        "path = \"hmdata/\"\n",
        "def read_data(day_oldest):\n",
        "    df_trans = pd.read_csv(path+\"transactions_train.csv.zip\",dtype=tran_dtypes)\n",
        "    df_trans[\"t_dat\"] = pd.to_datetime(df_trans[\"t_dat\"],format=\"%Y-%m-%d\")\n",
        "\n",
        "    df_trans = df_trans.query(f\"t_dat >= '{day_oldest}'\").copy()\n",
        "    df_trans = df_trans.drop_duplicates([\"customer_id\",\"article_id\",\"t_dat\"])\n",
        "    df_art,dict_vec = item_representation_1()\n",
        "    df_trans = df_trans.merge(df_art[[\"article_id\",\"product_code\",\"product_type_no\",\"graphical_appearance_no\",\"colour_group_code\",\"department_no\",\"index_code\",\"index_group_no\",\"section_no\",\"garment_group_no\"]],how=\"left\",on=\"article_id\")\n",
        "\n",
        "    return df_trans, df_art, dict_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4128aa41-0a7c-405c-a2c2-02a3e19678f2",
      "metadata": {
        "id": "4128aa41-0a7c-405c-a2c2-02a3e19678f2"
      },
      "source": [
        "Now we have all the ingredients we need -- we have a basic version of user representations and we have the article representations, and transactions data on which we can train our downstream task.\n",
        "\n",
        "The downstream task we consider is the task of predicting whether or not a user will purchase an article. This is the same task that we have been dealing with in the past 2 weeks.\n",
        "\n",
        "Lets define a train() function that will consider the start and end dates and split data based on these, generate the training data, do random negative sampling and train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0c7a4f-8e4d-42f7-b379-1ebc870375d9",
      "metadata": {
        "id": "5e0c7a4f-8e4d-42f7-b379-1ebc870375d9"
      },
      "outputs": [],
      "source": [
        "def train(user_representation_func):\n",
        "    #### Transaction start date say it is from 2019/9/23 and say we take 1 week data\n",
        "    day_start = datetime.datetime(2019,9,23) - datetime.timedelta(days=6)\n",
        "    #### Transaction end date\n",
        "    day_end = datetime.datetime(2019,9,23) - datetime.timedelta(days=0)\n",
        "    \n",
        "    ######## Splitting data based on date ###########################\n",
        "    ####### Train date ###########################################\n",
        "    ## Let's consider the training data for 1 year\n",
        "    day_start_hist = day_start - datetime.timedelta(days=366)\n",
        "    day_end_hist = day_start - datetime.timedelta(days=1)\n",
        "    \n",
        "    df_trans, df_art, dict_vec = read_data(day_oldest = datetime.datetime(2018,9,23))\n",
        "\n",
        "    df_cust = user_representation_func\n",
        "\n",
        "    query_date = f\"((t_dat >= '{day_start}') and (t_dat <= '{day_end}'))\"\n",
        "    top_art_all = df_trans.query(query_date ).groupby(\"article_id\")[\"t_dat\"].count().sort_values(ascending = False).index[:N].tolist()\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    ############### Create training data #################################################################################\n",
        "    \n",
        "    \n",
        "    list_df_buy = []\n",
        "    list_cust =[]\n",
        "    \n",
        "    # make positive samples\n",
        "    list_df_buy = df_trans.query(f\"(t_dat >= '{day_start}') and (t_dat <= '{day_end}') and (article_id in @top_art_all)\").drop_duplicates([\"customer_id\",\"article_id\"])[[\"customer_id\",\"article_id\"]].copy()\n",
        "    list_df_buy[\"target\"] = 1\n",
        "    list_cust = list_df_buy[\"customer_id\"].unique().tolist()\n",
        "        \n",
        "        \n",
        "    # make negative samples (random selection)\n",
        "    \n",
        "    list_df_nobuy = pd.concat([pd.DataFrame({\"customer_id\":x,\"article_id\":random.sample(top_art_all,nobuy)}) for x in list_cust])\n",
        "    list_df_nobuy[\"target\"] = 0\n",
        "    list_train = pd.concat([list_df_buy,list_df_nobuy]).drop_duplicates([\"customer_id\",\"article_id\"])\n",
        "    del list_df_nobuy\n",
        "\n",
        "    # add feature\n",
        "    df_train = pd.DataFrame()\n",
        "    \n",
        "    ########## Merging item features with the transactions data ###################################################\n",
        "    list_train = list_train.merge(df_art[[\"article_id\",\"product_code\",\"product_type_no\",\"graphical_appearance_no\",\"colour_group_code\",\"department_no\",\"index_code\",\"index_group_no\",\"section_no\",\"garment_group_no\"]],how=\"left\",on=\"article_id\")\n",
        "    \n",
        "    ######### Merging customer data with the above data ######################################\n",
        "    list_train = list_train.merge(df_cust, how=\"left\", on=\"customer_id\")\n",
        "    df_train = df_train.append(list_train)\n",
        "    del list_train\n",
        "    gc.collect()\n",
        "    \n",
        "    \n",
        "    # now that we have all the data in place, lets train the lgbm model\n",
        "\n",
        "    # train lgbm\n",
        "    X_train = df_train.drop([\"customer_id\",\"product_code\",\"product_type_no\",\"department_no\",\"target\"],axis=1)\n",
        "    y_train = df_train[\"target\"]\n",
        "    del df_train\n",
        "    \n",
        "    X_tr, X_va, y_tr, y_va = train_test_split(X_train,y_train,stratify = y_train)\n",
        "    d_tr = lgb.Dataset(X_tr, label=y_tr,  free_raw_data=False)\n",
        "    d_va = lgb.Dataset(X_va, label=y_va,  free_raw_data=False)\n",
        "    lgbm_model = lgb.train(lgb_params, train_set=d_tr, num_boost_round=n_round, valid_sets=[d_tr,d_va], verbose_eval=500, early_stopping_rounds=100)\n",
        "    \n",
        "    # save model\n",
        "    pd.to_pickle(lgbm_model,\"lgbm_model.pkl\")\n",
        "    del X_train, y_train, X_tr, X_va, y_tr, y_va, d_tr, d_va\n",
        "    gc.collect()\n",
        "    del df_trans, df_art, df_cust\n",
        "    gc.collect()\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb1b72d-7f50-4dc8-a44c-95dcf9c537d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afb1b72d-7f50-4dc8-a44c-95dcf9c537d2",
        "outputId": "0939e253-de85-4901-9cb6-f031e91faf92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[500]\ttraining's auc: 0.81024\tvalid_1's auc: 0.804482\n",
            "[1000]\ttraining's auc: 0.824578\tvalid_1's auc: 0.815429\n",
            "[1500]\ttraining's auc: 0.833414\tvalid_1's auc: 0.821087\n",
            "[2000]\ttraining's auc: 0.839664\tvalid_1's auc: 0.824432\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's auc: 0.839664\tvalid_1's auc: 0.824432\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train(user_representation_1())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GC4kWRLCbW8l",
      "metadata": {
        "id": "GC4kWRLCbW8l"
      },
      "outputs": [],
      "source": [
        "# keeps failing due to RAM, need to adjust trans data\n",
        "train(user_representation_2())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4b63a5-56ee-4bd2-b7b8-2aebb5299b31",
      "metadata": {
        "id": "2a4b63a5-56ee-4bd2-b7b8-2aebb5299b31"
      },
      "source": [
        "We have now trained a light gbm model using user_representation_1() function as the user representation technique. The key goals for part B of this week's project are to implement user_representation_2(), where we represent the user as the average of embeddings of their recently purchased articles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4940f48d-08e5-4130-be2c-d15622012620",
      "metadata": {
        "id": "4940f48d-08e5-4130-be2c-d15622012620"
      },
      "source": [
        "Once you have implemented the function, please note to change the line:\n",
        "\n",
        "df_cust = user_representation_1()\n",
        "\n",
        "to the appropriate function name and run re-train the model. Please report the performance numbers with each of the two user representations.\n",
        "\n",
        "This should complete the week 3 project!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ydLW7dPiuw-E",
      "metadata": {
        "id": "ydLW7dPiuw-E"
      },
      "source": [
        "### Optional task 1: training a Doc2Vec model\n",
        "\n",
        "If you want an extra challenge, you can try implementing Doc2vec representations in user_representation_3(). The Doc2vec model is an embedding learning method\n",
        "    that enables us to learn representations of a document.\n",
        "    We treat each user as a document, and the set of articles\n",
        "    the user has purchased as the set of words in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce141145-f5af-4f2d-9d94-f4bb50e6208f",
      "metadata": {
        "id": "ce141145-f5af-4f2d-9d94-f4bb50e6208f"
      },
      "source": [
        "### Optional task 2: training a sequential LSTM model\n",
        "\n",
        "Another optional task here would be to implement user_representation_4() where user representations are learnt by a sequential LSTM model. The LSTM model will need to be trained on a task -- the task itself could be the downstream task of predicting whether or not a user would purchase a given article given a sequence of previous articles. The final hidden layer of the lstm model can be used as the user representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88eb3b58-062c-4c96-b3f0-2db4407ce1b3",
      "metadata": {
        "id": "88eb3b58-062c-4c96-b3f0-2db4407ce1b3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "week3-ann-user-representations_BryanClark.ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-6.m89",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
